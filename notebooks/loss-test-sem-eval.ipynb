{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatic reload imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run notebooks as it would run if was one folder upper in the tree, enabling direct reference to source files\n",
    "import sys\n",
    "sys.path.insert(0, '../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "from src.utils.level_dict_sem_eval import hierarchy\n",
    "from src.model.hierarchical_loss_semeval import HierarchicalLossNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 GPUs available.\n",
      "Torch is using cuda!\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "        available_device = \"cuda\" \n",
    "else:\n",
    "    available_device = 'cpu'\n",
    "device = torch.device(available_device)\n",
    "\n",
    "print(f'{torch.cuda.device_count()} GPUs available.')\n",
    "print(f'Torch is using {device}!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hloss = HierarchicalLossNetwork(\n",
    "    hierarchical_labels=hierarchy,\n",
    "    device=device,\n",
    "    p_loss=3,\n",
    "    alpha=1,\n",
    "    beta=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Persuasion': {'Ethos (level 1)': {'Ad Hominem (level 2)': {'Ad Hominem (level 3)': {'Doubt': {},\n",
      "                                                                                      'Name Calling': {},\n",
      "                                                                                      'Reductio ad Hitlerum': {},\n",
      "                                                                                      'Smears': {},\n",
      "                                                                                      'Whataboutism - Ad Hominem (level 3)': {}}},\n",
      "                                    'Ethos (level 2)': {'Ethos (level 3)': {'Appeal to Authority - Ethos (level 3)': {},\n",
      "                                                                            'Bandwagon - Ethos (level 3)': {},\n",
      "                                                                            'Glittering Generalities': {},\n",
      "                                                                            'Transfer - Ethos (level 3)': {}}}},\n",
      "                'Logos (level 1)': {'Justification (level 2)': {'Justification (level 3)': {'Appeal to Authority - Justification (level 3)': {},\n",
      "                                                                                            'Appeal to Fear - Justification (level 3)': {},\n",
      "                                                                                            'Bandwagon - Justification (level 3)': {},\n",
      "                                                                                            'Flag Waving - Justification (level 3)': {},\n",
      "                                                                                            'Slogans': {}}},\n",
      "                                    'Logos (level 2)': {'Logos (level 3)': {'Intentional Vagueness': {},\n",
      "                                                                            'Repetition': {}}},\n",
      "                                    'Reasoning': {'Distraction': {'Red Herring': {},\n",
      "                                                                  'Straw Man': {},\n",
      "                                                                  'Whataboutism - Distraction': {}},\n",
      "                                                  'Simplification': {'Black & White Fallacy': {},\n",
      "                                                                     'Causal Oversimplification': {},\n",
      "                                                                     'Thought Termination ClichÃ©': {}}}},\n",
      "                'Pathos (level 1)': {'Pathos (level 2)': {'Pathos (level 3)': {'Appeal to Emotion (Visual)': {},\n",
      "                                                                               'Appeal to Fear - Pathos (level 3)': {},\n",
      "                                                                               'Exaggeration': {},\n",
      "                                                                               'Flag Waving - Pathos (level 3)': {},\n",
      "                                                                               'Loaded Language': {},\n",
      "                                                                               'Transfer - Pathos (level 3)': {}}}}}}\n"
     ]
    }
   ],
   "source": [
    "pprint(hierarchy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {0: {0: {0: {0: {}, 1: {}, 2: {}, 3: {}, 4: {}}},\n",
      "         1: {1: {5: {}, 6: {}, 7: {}, 8: {}}}},\n",
      "     1: {2: {2: {9: {}, 10: {}, 11: {}, 12: {}, 13: {}, 14: {}}}},\n",
      "     2: {3: {3: {15: {}, 16: {}, 17: {}, 18: {}, 19: {}}},\n",
      "         4: {4: {20: {}, 21: {}}},\n",
      "         5: {5: {22: {}, 23: {}, 24: {}}, 6: {25: {}, 26: {}, 27: {}}}}}}\n"
     ]
    }
   ],
   "source": [
    "pprint(hloss.hierarchical_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hloss.check_hierarchy(['Pathos (level 1)'], ['Pathos (level 2)'],hierarchy_representation='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2, 3, 4, 5],\n",
       " [0, 1, 2, 3, 4, 5, 6],\n",
       " [0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  13,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  19,\n",
       "  20,\n",
       "  21,\n",
       "  22,\n",
       "  23,\n",
       "  24,\n",
       "  25,\n",
       "  26,\n",
       "  27]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_labels_by_level = hloss.get_class_labels_by_level()\n",
    "hloss.label_to_index(class_labels_by_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "HierarchicalLossNetwork.get_children_by_index() missing 1 required positional argument: 'tree'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mhloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_children_by_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: HierarchicalLossNetwork.get_children_by_index() missing 1 required positional argument: 'tree'"
     ]
    }
   ],
   "source": [
    "hloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fake_predictions(predictions_index, numeric_hierarchy, device):\n",
    "    n_classes = {}\n",
    "    n_classes['superclass'] = len(list(numeric_hierarchy.keys()))\n",
    "    n_classes['subclass'] = len(np.ravel(list(hloss.numeric_hierarchy.values())))\n",
    "\n",
    "    fake_predictions = {}\n",
    "    fake_predictions['superclass'] = []\n",
    "    fake_predictions['subclass'] = []\n",
    "\n",
    "    for class_type in ['superclass', 'subclass']:\n",
    "        for example in predictions_index:\n",
    "            class_index = example[0 if class_type=='superclass' else 1]\n",
    "            fake_prediction = np.zeros(n_classes[class_type])\n",
    "            fake_prediction[class_index] = 1\n",
    "\n",
    "            fake_predictions[class_type].append(fake_prediction)\n",
    "        \n",
    "        \n",
    "        fake_predictions[class_type] = torch.Tensor(fake_predictions[class_type])\n",
    "        fake_predictions[class_type] = fake_predictions[class_type].to(device)\n",
    "\n",
    "    return [fake_predictions['superclass'], fake_predictions['subclass']]\n",
    "\n",
    "def make_fake_labels(labels, device):\n",
    "    tensor_labels = torch.Tensor(labels).to(device)\n",
    "    tensor_labels = [tensor_labels[:,0], tensor_labels[:,1]]\n",
    "    return tensor_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_index = [\n",
    "    [0, 55],  # Acerto; acertou superclasse, acertou subclasse, acertou dependencia\n",
    "    [0, 30],  # Erro;   acertou superclasse, errou   subclasse, acertou dependencia\n",
    "    [0, 32],  # Erro;   acertou superclasse, errou   subclasse, errou   dependencia\n",
    "    [1, 55],  # Erro;   errou   superclasse, acertou subclasse, errou   dependencia\n",
    "    [1, 32],  # Erro;   errou   superclasse, errou   subclasse, acertou dependencia\n",
    "    [1, 62],  # Erro;   errou   superclasse, errou   subclasse, errou   dependencia\n",
    "              # Erro;   acertou superclasse, acertou subclasse, errou   dependencia <- impossivel pois se acertar os dois acerta a dependencia\n",
    "              # Erro;   errou   superclasse, acertou subclasse, acertou dependencia <- impossivel\n",
    "]\n",
    "labels = [\n",
    "    [0, 55],\n",
    "    [0, 55],\n",
    "    [0, 55],\n",
    "    [0, 55],\n",
    "    [0, 55],\n",
    "    [0, 55],\n",
    "]\n",
    "\n",
    "error_type = [\n",
    "    'Acerto; acertou superclasse, acertou subclasse, acertou dependencia',\n",
    "    'Erro;   acertou superclasse, errou   subclasse, acertou dependencia',\n",
    "    'Erro;   acertou superclasse, errou   subclasse, errou   dependencia',\n",
    "    'Erro;   errou   superclasse, acertou subclasse, errou   dependencia',\n",
    "    'Erro;   errou   superclasse, errou   subclasse, acertou dependencia',\n",
    "    'Erro;   errou   superclasse, errou   subclasse, errou   dependencia'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0.]], device='cuda:0'),\n",
       " tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_predictions = make_fake_predictions(predictions_index, hloss.numeric_hierarchy, device)\n",
    "fake_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superclasses_predictions: tensor([0, 0, 0, 1, 1, 1], device='cuda:0')\n",
      "sublcasses_predictions: tensor([55, 30, 32, 55, 32, 62], device='cuda:0')\n",
      "fake_labels: [tensor([0., 0., 0., 0., 0., 0.], device='cuda:0'), tensor([55., 55., 55., 55., 55., 55.], device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "superclasses_predictions = torch.argmax(nn.Softmax(dim=1)(fake_predictions[0]), dim=1)\n",
    "sublcasses_predictions = torch.argmax(nn.Softmax(dim=1)(fake_predictions[1]), dim=1)\n",
    "\n",
    "print(f'superclasses_predictions: {superclasses_predictions}')\n",
    "print(f'sublcasses_predictions: {sublcasses_predictions}')\n",
    "\n",
    "fake_labels = make_fake_labels(labels, device)\n",
    "print(f'fake_labels: {fake_labels}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\"nll_loss_forward_reduce_cuda_kernel_2d_index\" not implemented for 'Float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mhloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_lloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfake_predictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfake_labels\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projetos/Deep_Hierarchical_Classification/notebooks/../src/model/hierarchical_loss.py:54\u001b[0m, in \u001b[0;36mHierarchicalLossNetwork.calculate_lloss\u001b[0;34m(self, predictions, true_labels)\u001b[0m\n\u001b[1;32m     51\u001b[0m lloss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal_level):\n\u001b[0;32m---> 54\u001b[0m     lloss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCrossEntropyLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m[\u001b[49m\u001b[43ml\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[43ml\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha \u001b[38;5;241m*\u001b[39m lloss\n",
      "File \u001b[0;32m~/projetos/Deep_Hierarchical_Classification/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projetos/Deep_Hierarchical_Classification/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/projetos/Deep_Hierarchical_Classification/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:1179\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1181\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projetos/Deep_Hierarchical_Classification/venv/lib/python3.10/site-packages/torch/nn/functional.py:3059\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3058\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3059\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \"nll_loss_forward_reduce_cuda_kernel_2d_index\" not implemented for 'Float'"
     ]
    }
   ],
   "source": [
    "hloss.calculate_lloss(fake_predictions, fake_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12., device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# l_loss = hloss.calculate_lloss(fake_predictions, fake_labels)\n",
    "# print(f'LLoss: {lloss}')\n",
    "\n",
    "d_loss = hloss.calculate_dloss(fake_predictions, fake_labels)\n",
    "d_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Teste 1 - label: [0, 55] | prediction: [0, 55]\n",
      "Acerto; acertou superclasse, acertou subclasse, acertou dependencia\n",
      "Dloss: 0.0\n",
      "\n",
      "# Teste 2 - label: [0, 55] | prediction: [0, 30]\n",
      "Erro;   acertou superclasse, errou   subclasse, acertou dependencia\n",
      "Dloss: 0.0\n",
      "\n",
      "# Teste 3 - label: [0, 55] | prediction: [0, 32]\n",
      "Erro;   acertou superclasse, errou   subclasse, errou   dependencia\n",
      "Dloss: 2.0\n",
      "\n",
      "# Teste 4 - label: [0, 55] | prediction: [1, 55]\n",
      "Erro;   errou   superclasse, acertou subclasse, errou   dependencia\n",
      "Dloss: 2.0\n",
      "\n",
      "# Teste 5 - label: [0, 55] | prediction: [1, 32]\n",
      "Erro;   errou   superclasse, errou   subclasse, acertou dependencia\n",
      "Dloss: 0.0\n",
      "\n",
      "# Teste 6 - label: [0, 55] | prediction: [1, 62]\n",
      "Erro;   errou   superclasse, errou   subclasse, errou   dependencia\n",
      "Dloss: 8.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(predictions_index)):\n",
    "    fake_predictions = make_fake_predictions([predictions_index[i]], hloss.numeric_hierarchy, device)\n",
    "    fake_labels = make_fake_labels([labels[i]], device)\n",
    "\n",
    "    d_loss = hloss.calculate_dloss(fake_predictions, fake_labels)\n",
    "    \n",
    "    print(f'# Teste {i+1} - label: {labels[i]} | prediction: {predictions_index[i]}')\n",
    "    print(error_type[i])\n",
    "    print(f'Dloss: {d_loss}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 55]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
